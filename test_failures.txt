.venv\Scripts\pytest : C:\Us
ers\USER\.gemini\antigravity
\scratch\mcp-python-auditor\
.venv\Lib\site-packages\pyte
st_asyncio\plugin.py:208: 
PytestDeprecationWarning: 
The configuration option "as
yncio_default_fixture_loop_s
cope" is unset.
At line:1 char:1
+ .venv\Scripts\pytest 
tests --tb=line -q 2>&1 | 
Out-File -FilePath tes ...
+ ~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~
    + CategoryInfo          
    : NotSpecified: (C:\Us  
  ers\USER\....cope" is u   
 nset.:String) [], Remot    
eException
    + FullyQualifiedErrorId 
    : NativeCommandError
 
The event loop scope for 
asynchronous fixtures will 
default to the fixture 
caching scope. Future 
versions of pytest-asyncio 
will default the loop scope 
for asynchronous fixtures 
to function scope. Set the 
default fixture loop scope 
explicitly in order to 
avoid unexpected behavior 
in the future. Valid 
fixture loop scopes are: 
"function", "class", 
"module", "package", 
"session"

  warnings.warn(PytestDeprec
ationWarning(_DEFAULT_FIXTUR
E_LOOP_SCOPE_UNSET))
============================= test session starts =============================
platform win32 -- Python 3.13.11, pytest-8.3.3, pluggy-1.6.0
rootdir: C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor
configfile: pyproject.toml
plugins: anyio-4.12.1, asyncio-0.24.0, cov-5.0.0
asyncio: mode=Mode.STRICT, default_loop_scope=None
collected 108 items

tests\e2e\test_audit_workflows.py Fs....                                 [  5%]
tests\integration\test_tools_integration.py ...F..                       [ 11%]
tests\mcp\test_mcp_server.py ....                                        [ 14%]
tests\test_analyzer_agent.py .....                                       [ 19%]
tests\test_api.py ........F.                                             [ 28%]
tests\test_parallel_audit.py ...                                         [ 31%]
tests\test_pr_gatekeeper.py ...........F.                                [ 43%]
tests\test_remote_audit.py .....FF.F....                                 [ 55%]
tests\test_tool_fixes.py .                                               [ 56%]
tests\test_tools.py .....                                                [ 61%]
tests\tools\test_individual_tools.py .............F.                     [ 75%]
tests\unit\test_dependencies.py .....                                    [ 79%]
tests\unit\test_scoring.py ......                                        [ 85%]
tests\unit\test_venv_exclusion.py ................                       [100%]

================================== FAILURES ===================================
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\e2e\test_audit_workflows.py:75: AssertionError: assert 'failed' == 'completed'
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\integration\test_tools_integration.py:101: AssertionError: assert 'cleanup_available' in ['analyzed', 'clean', 'issues_found', 'skipped', 'error', 'success']
C:\\Users\\USER\\.gemini\\antigravity\\scratch\\mcp-python-auditor\\tests\\test_api.py:151: AssertionError: assert 'Project Audit' in '## \U0001f4ca Tool Execution Summary\\n\\n| Tool | Status | Details |\\n|------|--------|----------|\\n| \U0001f4c1 Structure | \u2139\ufe0f Info | 2...**Verified:** No virtual environment leaks detected.\\n\u2705 **Verified:** Scan scope strictly limited to project source.\\n'
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\test_pr_gatekeeper.py:320: assert 80 < 80
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\test_remote_audit.py:131: AssertionError: assert 'branch' in 'repository not found: https://github.com/user/repo.git'
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\test_remote_audit.py:150: AssertionError: assert 'timeout' in 'clone operation timed out (>5 minutes)'
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\test_remote_audit.py:195: AssertionError: assert 'no Python files' in 'repository cloned successfully but contains no python files'
C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\tests\tools\test_individual_tools.py:194: assert 'timeout' in 'def run_bandit(path: Path) -> dict:\n    """Run FastAudit (Ruff) for security and quality checks."""\n    try:\n     ...xception as e:\n        return {"tool": "ruff", "status": "error", "error": str(e), "issues": [], "total_issues": 0}\n'
============================== warnings summary ===============================
app\tools\tests_tool.py:14
  C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\app\tools\tests_tool.py:14: PytestCollectionWarning: cannot collect test class 'TestsTool' because it has a __init__ constructor (from: tests/test_tool_fixes.py)
    class TestsTool(BaseTool):

tests/e2e/test_audit_workflows.py::TestFullAuditWorkflow::test_complete_audit_cycle
  C:\Users\USER\.gemini\antigravity\scratch\mcp-python-auditor\.venv\Lib\site-packages\astor\op_util.py:92: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead
    precedence_data = dict((getattr(ast, x, None), z) for x, y, z in op_data)

tests/test_analyzer_agent.py::test_analyze_project
tests/test_analyzer_agent.py::test_analyze_project
tests/test_analyzer_agent.py::test_analyze_project
  The verify_requirements argument is now a no-op and is deprecated for removal. Remove the argument from calls.

tests/test_analyzer_agent.py::test_analyze_project
  ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED tests/e2e/test_audit_workflows.py::TestFullAuditWorkflow::test_complete_audit_cycle
FAILED tests/integration/test_tools_integration.py::TestToolIntegration::test_full_audit_workflow
FAILED tests/test_api.py::test_get_report - AssertionError: assert 'Project A...
FAILED tests/test_pr_gatekeeper.py::TestAuditPRChanges::test_audit_pr_skip_tests_low_score
FAILED tests/test_remote_audit.py::TestRemoteAuditCloning::test_branch_not_found
FAILED tests/test_remote_audit.py::TestRemoteAuditCloning::test_clone_timeout
FAILED tests/test_remote_audit.py::TestRemoteAuditExecution::test_no_python_files
FAILED tests/tools/test_individual_tools.py::TestToolErrorHandling::test_tool_timeout_handling
============ 8 failed, 99 passed, 1 skipped, 6 warnings in 17.79s =============
